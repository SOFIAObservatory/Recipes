{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOFIA data retrieval\n",
    "-------------------\n",
    "**Aim**: Download SOFIA data through the Infrared Science Archive (IRSA)<br />\n",
    "**Data**: 30 Doradus HAWC+ public dataset<br />\n",
    "**Instrument**: All<br />\n",
    "**Documentation**: [Science Archive](https://www.sofia.usra.edu/data/science-archive).<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "* Download data manually through the ISRA website\n",
    "* Explore file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this `jupyter` recipe, we explain how to download SOFIA data through the Infrared Science Archive (IRSA).\n",
    "\n",
    "This cookbook recipe follows the SOFIA press release of 30 Doradus observations: [SOFIA Reveals Never-Before-Seen Magnetic Field Details](https://www.sofia.usra.edu/multimedia/science-results-archive/sofia-reveals-never-seen-magnetic-field-details).\n",
    "\n",
    "The Level 4 reduced data from this program has been released immediately to the public and is available on the Infrared Science Archive [(IRSA)](https://irsa.ipac.caltech.edu/Missions/sofia.html).  This notebook will guide the reader through downloading the 30 Doradus data manually through the ISRA website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading HAWC+ Data\n",
    "\n",
    "- Fill in the following fields\n",
    "- Spatial constraints:\n",
    "  - Coordinates or object name: `30 Dor` from drop-down menu\n",
    "  - Radius: `600 arcseconds`\n",
    "- Click on the arrow next to Observation Constraints to open the drop-down options. \n",
    "- Observation Constraints:\n",
    "  - Observation Date: From: `2018-01-01` To: `2019-01-01`\n",
    "- Instrument Constraints\n",
    "  - Select `HAWC+`\n",
    "- Data Product Constraints:\n",
    "  - Processing Level: `Level 4`\n",
    "  - Click the `Search` button\n",
    "- After the results load, select the checkboxes next to the Column header AOR ID to select all data files. All files should now have a blue check indicating selection. \n",
    "- Click `Prepare Download`\n",
    "- Fill in Title as `HAWC+_example_data`\n",
    "- Click `Prepare Download`\n",
    "- After a few minutes, the data will be downloaded locally.\n",
    "- For more information, consult the [HAWC+ Data Handbook](https://www.sofia.usra.edu/sites/default/files/Instruments/HAWC_PLUS/Documents/hawc_data_handbook.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ISRA Search Results](../figs/isra_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results will show files (fits) including descriptions of the file metadata. Included in this metadata is the \"Quality Assurance\" comments (shown with the red ellipse) with specific notes from the instrument scientists during the observations. These include notes about data quality, observing complications, and if the observations was an aquisition observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOFIA Data Organization\n",
    "After downloading the SOFIA data to your working directory you will want to unzip it, which will produce a directory structure like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    ".\n",
    "└── HAWC+_example_data\n",
    "    ├── level4\n",
    "    │   └── p5813\n",
    "    │       └── F0484_HA_POL_7600018_HAWCHWPC_PMP_022-114.fits\n",
    "    └── missions\n",
    "        ├── 2018-07-05_HA_F481\n",
    "        │   └── p5827\n",
    "        │       └── F0481_HA_POL_7600012_HAWDHWPD_PMP_050-083.fits\n",
    "        ├── 2018-07-07_HA_F483\n",
    "        │   └── p5646\n",
    "        │       └── F0483_HA_POL_7600014_HAWCHWPC_PMP_022-065.fits\n",
    "        ├── 2018-07-11_HA_F484\n",
    "        │   └── p5648\n",
    "        │       └── F0484_HA_POL_7600017_HAWCHWPC_PMP_065-114.fits\n",
    "        └── 2018-07-12_HA_F485\n",
    "            └── p5658\n",
    "                ├── g1\n",
    "                │   └── F0485_HA_POL_76000110_HAWAHWPA_PMP_043-052.fits\n",
    "                └── g2\n",
    "                    └── F0485_HA_POL_7600019_HAWEHWPE_PMP_055-075.fits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following features of this data bundle.\n",
    "\n",
    "- Each `fits` file in the 'missions' directory corresponds to data from a single AOR (or a different filter element) obtained on a single flight\n",
    "- Each subdirectory under missions corresponds to a single flight\n",
    "- `fits` files under 'level4' correspond to data combined from several flights\n",
    "- If multiple filters were observed on the same flight, they will be further divided into subdirectories (g1/g2 on the last line)\n",
    "\n",
    "Note that two observations were made with the same filter (HAWC C, $89\\,\\mathrm{\\mu m}$).  These files, `F0483_HA_POL_7600014_HAWCHWPC_PMP_022-065.fits` and `F0484_HA_POL_7600017_HAWCHWPC_PMP_065-114.fits`, were combined into one:\n",
    "\n",
    "`level4->p5813->F0484_HA_POL_7600018_HAWCHWPC_PMP_022-114.fits`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to keep the `fits` files nested, or copy them into one directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    ".\n",
    "└── sofia_data\n",
    "    ├── F0481_HA_POL_7600012_HAWDHWPD_PMP_050-083.fits\n",
    "    ├── F0483_HA_POL_7600014_HAWCHWPC_PMP_022-065.fits\n",
    "    ├── F0484_HA_POL_7600017_HAWCHWPC_PMP_065-114.fits\n",
    "    ├── F0484_HA_POL_7600018_HAWCHWPC_PMP_022-114.fits\n",
    "    ├── F0485_HA_POL_76000110_HAWAHWPA_PMP_043-052.fits\n",
    "    └── F0485_HA_POL_7600019_HAWEHWPE_PMP_055-075.fits\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py:273: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 273 of the file /Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  root = BeautifulSoup(response.text)\n",
      "/Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py:311: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 311 of the file /Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  root = BeautifulSoup(response.text)\n",
      "/Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py:365: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 365 of the file /Users/srgoldma/opt/anaconda3/lib/python3.9/site-packages/astroquery/ipac/irsa/ibe/core.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  root = BeautifulSoup(response.text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['obsid',\n",
       " 'planeid',\n",
       " 'productid',\n",
       " 'creatorid',\n",
       " 'metarelease',\n",
       " 'datarelease',\n",
       " 'calibrationlevel',\n",
       " 'dataproducttype',\n",
       " 'quality_flag',\n",
       " 'metrics_sourcenumberdensity',\n",
       " 'metrics_background',\n",
       " 'metrics_backgroundstddev',\n",
       " 'metrics_fluxdensitylimit',\n",
       " 'metrics_maglimit',\n",
       " 'position_dimension_naxis1',\n",
       " 'position_dimension_naxis2',\n",
       " 'position_resolution',\n",
       " 'position_samplesize',\n",
       " 'position_timedependent',\n",
       " 'energy_bounds_lower',\n",
       " 'energy_bounds_upper',\n",
       " 'energy_bounds_samples',\n",
       " 'energy_emband',\n",
       " 'energy_dimension',\n",
       " 'energy_resolvingpower',\n",
       " 'energy_samplesize',\n",
       " 'energy_bandpassname',\n",
       " 'energy_transition_species',\n",
       " 'energy_transition_transition',\n",
       " 'energy_restwav',\n",
       " 'time_bounds_lower',\n",
       " 'time_bounds_upper',\n",
       " 'time_bounds_samples',\n",
       " 'time_dimension',\n",
       " 'time_resolution',\n",
       " 'time_samplesize',\n",
       " 'time_exposure',\n",
       " 'polarization_states',\n",
       " 'polarization_dimension',\n",
       " 'provenance_name',\n",
       " 'provenance_reference',\n",
       " 'provenance_version',\n",
       " 'provenance_project',\n",
       " 'provenance_producer',\n",
       " 'provenance_runid',\n",
       " 'provenance_lastexecuted',\n",
       " 'provenance_keywords',\n",
       " 'ipac_gid',\n",
       " 'mission_id',\n",
       " 'poly',\n",
       " 'pt',\n",
       " 'ipac_pub_date',\n",
       " 'lastmodified']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from astroquery.ipac.irsa.ibe import Ibe\n",
    "# Ibe.list_tables('sofia','sofia.plane')\n",
    "# Ibe.query_region(coordinate='19:41:57.080, 16:44:39.64', mission='sofia', dataset='sofia.plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
